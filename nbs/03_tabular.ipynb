{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from timeseries_fastai.imports import *\n",
    "from timeseries_fastai.core import *\n",
    "from fastai2.basics import *\n",
    "from fastai2.torch_core import *\n",
    "from fastai2.vision.data import get_grid\n",
    "from fastai2.tabular.core import TabularProc, _TabIloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "> DataBlock API to construct the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a DataBlock to process our UCR datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ucr_path = untar_data(URLs.UCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from: /home/tc256760/.fastai/data/Univariate2018_arff/StarLightCurves\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = load_df_ucr(ucr_path, 'StarLightCurves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att1016</th>\n",
       "      <th>att1017</th>\n",
       "      <th>att1018</th>\n",
       "      <th>att1019</th>\n",
       "      <th>att1020</th>\n",
       "      <th>att1021</th>\n",
       "      <th>att1022</th>\n",
       "      <th>att1023</th>\n",
       "      <th>att1024</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.537303</td>\n",
       "      <td>0.531103</td>\n",
       "      <td>0.528503</td>\n",
       "      <td>0.529403</td>\n",
       "      <td>0.533603</td>\n",
       "      <td>0.540903</td>\n",
       "      <td>0.551103</td>\n",
       "      <td>0.564003</td>\n",
       "      <td>0.579603</td>\n",
       "      <td>0.597603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546903</td>\n",
       "      <td>0.545903</td>\n",
       "      <td>0.543903</td>\n",
       "      <td>0.541003</td>\n",
       "      <td>0.537203</td>\n",
       "      <td>0.532303</td>\n",
       "      <td>0.526403</td>\n",
       "      <td>0.519503</td>\n",
       "      <td>0.511403</td>\n",
       "      <td>b'3'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.588398</td>\n",
       "      <td>0.593898</td>\n",
       "      <td>0.599098</td>\n",
       "      <td>0.604098</td>\n",
       "      <td>0.608798</td>\n",
       "      <td>0.613397</td>\n",
       "      <td>0.617797</td>\n",
       "      <td>0.622097</td>\n",
       "      <td>0.626097</td>\n",
       "      <td>0.630097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237399</td>\n",
       "      <td>0.246499</td>\n",
       "      <td>0.256199</td>\n",
       "      <td>0.266499</td>\n",
       "      <td>0.277399</td>\n",
       "      <td>0.288799</td>\n",
       "      <td>0.300899</td>\n",
       "      <td>0.313599</td>\n",
       "      <td>0.326899</td>\n",
       "      <td>b'3'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.049900</td>\n",
       "      <td>-0.041500</td>\n",
       "      <td>-0.033400</td>\n",
       "      <td>-0.025600</td>\n",
       "      <td>-0.018100</td>\n",
       "      <td>-0.010800</td>\n",
       "      <td>-0.003800</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.015900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173801</td>\n",
       "      <td>-0.161601</td>\n",
       "      <td>-0.149201</td>\n",
       "      <td>-0.136401</td>\n",
       "      <td>-0.123201</td>\n",
       "      <td>-0.109701</td>\n",
       "      <td>-0.095901</td>\n",
       "      <td>-0.081701</td>\n",
       "      <td>-0.067100</td>\n",
       "      <td>b'1'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.337005</td>\n",
       "      <td>1.319805</td>\n",
       "      <td>1.302905</td>\n",
       "      <td>1.286305</td>\n",
       "      <td>1.270005</td>\n",
       "      <td>1.254005</td>\n",
       "      <td>1.238304</td>\n",
       "      <td>1.223005</td>\n",
       "      <td>1.208104</td>\n",
       "      <td>1.193504</td>\n",
       "      <td>...</td>\n",
       "      <td>1.288905</td>\n",
       "      <td>1.298505</td>\n",
       "      <td>1.307705</td>\n",
       "      <td>1.316505</td>\n",
       "      <td>1.324905</td>\n",
       "      <td>1.332805</td>\n",
       "      <td>1.340205</td>\n",
       "      <td>1.347005</td>\n",
       "      <td>1.353205</td>\n",
       "      <td>b'3'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.769801</td>\n",
       "      <td>0.775301</td>\n",
       "      <td>0.780401</td>\n",
       "      <td>0.785101</td>\n",
       "      <td>0.789401</td>\n",
       "      <td>0.793301</td>\n",
       "      <td>0.796801</td>\n",
       "      <td>0.799901</td>\n",
       "      <td>0.802601</td>\n",
       "      <td>0.805101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.742401</td>\n",
       "      <td>0.744501</td>\n",
       "      <td>0.747301</td>\n",
       "      <td>0.750701</td>\n",
       "      <td>0.754801</td>\n",
       "      <td>0.759501</td>\n",
       "      <td>0.765001</td>\n",
       "      <td>0.771301</td>\n",
       "      <td>0.778401</td>\n",
       "      <td>b'3'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       att1      att2      att3      att4      att5      att6      att7  \\\n",
       "0  0.537303  0.531103  0.528503  0.529403  0.533603  0.540903  0.551103   \n",
       "1  0.588398  0.593898  0.599098  0.604098  0.608798  0.613397  0.617797   \n",
       "2 -0.049900 -0.041500 -0.033400 -0.025600 -0.018100 -0.010800 -0.003800   \n",
       "3  1.337005  1.319805  1.302905  1.286305  1.270005  1.254005  1.238304   \n",
       "4  0.769801  0.775301  0.780401  0.785101  0.789401  0.793301  0.796801   \n",
       "\n",
       "       att8      att9     att10  ...   att1016   att1017   att1018   att1019  \\\n",
       "0  0.564003  0.579603  0.597603  ...  0.546903  0.545903  0.543903  0.541003   \n",
       "1  0.622097  0.626097  0.630097  ...  0.237399  0.246499  0.256199  0.266499   \n",
       "2  0.003000  0.009600  0.015900  ... -0.173801 -0.161601 -0.149201 -0.136401   \n",
       "3  1.223005  1.208104  1.193504  ...  1.288905  1.298505  1.307705  1.316505   \n",
       "4  0.799901  0.802601  0.805101  ...  0.742401  0.744501  0.747301  0.750701   \n",
       "\n",
       "    att1020   att1021   att1022   att1023   att1024  target  \n",
       "0  0.537203  0.532303  0.526403  0.519503  0.511403    b'3'  \n",
       "1  0.277399  0.288799  0.300899  0.313599  0.326899    b'3'  \n",
       "2 -0.123201 -0.109701 -0.095901 -0.081701 -0.067100    b'1'  \n",
       "3  1.324905  1.332805  1.340205  1.347005  1.353205    b'3'  \n",
       "4  0.754801  0.759501  0.765001  0.771301  0.778401    b'3'  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      3\n",
       "1      3\n",
       "2      1\n",
       "3      3\n",
       "4      3\n",
       "      ..\n",
       "995    2\n",
       "996    3\n",
       "997    1\n",
       "998    3\n",
       "999    3\n",
       "Name: target, Length: 1000, dtype: int64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['target'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['att1', 'att2', 'att3', 'att4', 'att5']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_cols = df_train.columns[slice(0,-1)].to_list()\n",
    "x_cols[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TabularTS(CollBase, GetAttr, FilteredBase):\n",
    "    \"A `DataFrame` wrapper that knows which cols are x/y, and returns rows in `__getitem__`\"\n",
    "    _default, with_cont='procs',True\n",
    "    def __init__(self, df, procs=None, x_names=None, y_names=None, block_y=None, splits=None,\n",
    "                 do_setup=True, device=None, inplace=False):\n",
    "        if inplace and splits is not None:\n",
    "            warn(\"Using inplace with splits will trigger a pandas error. Set `pd.options.mode.chained_assignment=None` to avoid it.\")\n",
    "        if not inplace: df = df.copy()\n",
    "        if splits is not None: df = df.iloc[sum(splits, [])]\n",
    "        self.dataloaders = delegates(self._dl_type.__init__)(self.dataloaders)\n",
    "        super().__init__(df)\n",
    "\n",
    "        self.x_names,self.y_names,self.device = L(x_names),L(y_names),device\n",
    "        if block_y is None and self.y_names:\n",
    "            # Make ys categorical if they're not numeric\n",
    "            ys = df[self.y_names]\n",
    "            if len(ys.select_dtypes(include='number').columns)!=len(ys.columns): block_y = CategoryBlock()\n",
    "            else: block_y = RegressionBlock()\n",
    "        if block_y is not None and do_setup:\n",
    "            if callable(block_y): block_y = block_y()\n",
    "            procs = L(procs) + block_y.type_tfms\n",
    "        self.procs = Pipeline(procs)\n",
    "        self.split = len(df) if splits is None else len(splits[0])\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    def new(self, df):\n",
    "        return type(self)(df, do_setup=False, block_y=TransformBlock(),\n",
    "                          **attrdict(self, 'procs','x_names','y_names', 'device'))\n",
    "    \n",
    "    def subset(self, i): return self.new(self.items[slice(0,self.split) if i==0 else slice(self.split,len(self))])\n",
    "    def copy(self): self.items = self.items.copy(); return self\n",
    "    def decode(self): return self.procs.decode(self)\n",
    "    def decode_row(self, row): return self.new(pd.DataFrame(row).T).decode().items.iloc[0]\n",
    "    def show(self, max_n=10, **kwargs): display_df(self.new(self.all_cols[:max_n]).decode().items)\n",
    "    def setup(self): self.procs.setup(self)\n",
    "    def process(self): self.procs(self)\n",
    "    def loc(self): return self.items.loc\n",
    "    def iloc(self): return _TabIloc(self)\n",
    "    def targ(self): return self.items[self.y_names]\n",
    "    def x_names (self): return self.x_names\n",
    "    def n_subsets(self): return 2\n",
    "    def y(self): return self[self.y_names[0]]\n",
    "    def new_empty(self): return self.new(pd.DataFrame({}, columns=self.items.columns))\n",
    "    def to_device(self, d=None):\n",
    "        self.device = d\n",
    "        return self\n",
    "    \n",
    "    def all_col_names (self): \n",
    "        ys = [n for n in self.y_names if n in self.items.columns]\n",
    "        return self.x_names + self.y_names if len(ys) == len(self.y_names) else self.x_names\n",
    "\n",
    "properties(TabularTS,'loc','iloc','targ','all_col_names','n_subsets','y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tts = TabularTS(df_train, x_names=x_cols, y_names='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       att1      att2      att3      att4      att5      att6      att7  \\\n",
       "0  0.537303  0.531103  0.528503  0.529403  0.533603  0.540903  0.551103   \n",
       "1  0.588398  0.593898  0.599098  0.604098  0.608798  0.613397  0.617797   \n",
       "2 -0.049900 -0.041500 -0.033400 -0.025600 -0.018100 -0.010800 -0.003800   \n",
       "3  1.337005  1.319805  1.302905  1.286305  1.270005  1.254005  1.238304   \n",
       "\n",
       "       att8      att9     att10  ...   att1016   att1017   att1018   att1019  \\\n",
       "0  0.564003  0.579603  0.597603  ...  0.546903  0.545903  0.543903  0.541003   \n",
       "1  0.622097  0.626097  0.630097  ...  0.237399  0.246499  0.256199  0.266499   \n",
       "2  0.003000  0.009600  0.015900  ... -0.173801 -0.161601 -0.149201 -0.136401   \n",
       "3  1.223005  1.208104  1.193504  ...  1.288905  1.298505  1.307705  1.316505   \n",
       "\n",
       "    att1020   att1021   att1022   att1023   att1024  target  \n",
       "0  0.537203  0.532303  0.526403  0.519503  0.511403    b'3'  \n",
       "1  0.277399  0.288799  0.300899  0.313599  0.326899    b'3'  \n",
       "2 -0.123201 -0.109701 -0.095901 -0.081701 -0.067100    b'1'  \n",
       "3  1.324905  1.332805  1.340205  1.347005  1.353205    b'3'  \n",
       "\n",
       "[4 rows x 1025 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts.iloc[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TSPandas(TabularTS):\n",
    "    def transform(self, cols, f, all_col=True): \n",
    "        if not all_col: cols = [c for c in cols if c in self.items.columns]\n",
    "        if len(cols) > 0: self[cols] = self[cols].transform(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _add_prop(cls, nm):\n",
    "    @property\n",
    "    def f(o): return o[list(getattr(o,nm+'_names'))]\n",
    "    @f.setter\n",
    "    def fset(o, v): o[getattr(o,nm+'_names')] = v\n",
    "    setattr(cls, nm+'s', f)\n",
    "    setattr(cls, nm+'s', fset)\n",
    "\n",
    "_add_prop(TabularTS, 'y')\n",
    "_add_prop(TabularTS, 'x')\n",
    "_add_prop(TabularTS, 'all_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TSPandas(df_train, x_names=x_cols, y_names='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       att1      att2      att3      att4      att5      att6      att7  \\\n",
       "0  0.537303  0.531103  0.528503  0.529403  0.533603  0.540903  0.551103   \n",
       "1  0.588398  0.593898  0.599098  0.604098  0.608798  0.613397  0.617797   \n",
       "2 -0.049900 -0.041500 -0.033400 -0.025600 -0.018100 -0.010800 -0.003800   \n",
       "3  1.337005  1.319805  1.302905  1.286305  1.270005  1.254005  1.238304   \n",
       "4  0.769801  0.775301  0.780401  0.785101  0.789401  0.793301  0.796801   \n",
       "\n",
       "       att8      att9     att10  ...   att1016   att1017   att1018   att1019  \\\n",
       "0  0.564003  0.579603  0.597603  ...  0.546903  0.545903  0.543903  0.541003   \n",
       "1  0.622097  0.626097  0.630097  ...  0.237399  0.246499  0.256199  0.266499   \n",
       "2  0.003000  0.009600  0.015900  ... -0.173801 -0.161601 -0.149201 -0.136401   \n",
       "3  1.223005  1.208104  1.193504  ...  1.288905  1.298505  1.307705  1.316505   \n",
       "4  0.799901  0.802601  0.805101  ...  0.742401  0.744501  0.747301  0.750701   \n",
       "\n",
       "    att1020   att1021   att1022   att1023   att1024  target  \n",
       "0  0.537203  0.532303  0.526403  0.519503  0.511403    b'3'  \n",
       "1  0.277399  0.288799  0.300899  0.313599  0.326899    b'3'  \n",
       "2 -0.123201 -0.109701 -0.095901 -0.081701 -0.067100    b'1'  \n",
       "3  1.324905  1.332805  1.340205  1.347005  1.353205    b'3'  \n",
       "4  0.754801  0.759501  0.765001  0.771301  0.778401    b'3'  \n",
       "\n",
       "[5 rows x 1025 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _apply_cats (voc, add, c):\n",
    "    if not is_categorical_dtype(c):\n",
    "        return pd.Categorical(c, categories=voc[c.name][add:]).codes+add\n",
    "    return c.cat.codes+add #if is_categorical_dtype(c) else c.map(voc[c.name].o2i)\n",
    "def _decode_cats(voc, c): return c.map(dict(enumerate(voc[c.name].items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# class Categorify(TabularProc):\n",
    "#     \"Transform the categorical variables to that type.\"\n",
    "#     order = 1\n",
    "#     def setups(self, to):\n",
    "#         self.classes = {n:CategoryMap(to.iloc[:,n].items, add_na=(n in to.cat_names)) for n in to.cat_names}\n",
    "\n",
    "#     def encodes(self, to): to.transform(to.cat_names, partial(_apply_cats, self.classes, 1))\n",
    "#     def decodes(self, to): to.transform(to.cat_names, partial(_decode_cats, self.classes))\n",
    "#     def __getitem__(self,k): return self.classes[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@Categorize\n",
    "def setups(self, to:TabularTS):\n",
    "    if len(to.y_names) > 0:\n",
    "        self.vocab = CategoryMap(getattr(to, 'train', to).iloc[:,to.y_names[0]].items)\n",
    "        self.c = len(self.vocab)\n",
    "    return self(to)\n",
    "\n",
    "@Categorize\n",
    "def encodes(self, to:TabularTS):\n",
    "    to.transform(to.y_names, partial(_apply_cats, {n: self.vocab for n in to.y_names}, 0), all_col=False)\n",
    "    return to\n",
    "\n",
    "@Categorize\n",
    "def decodes(self, to:TabularTS):\n",
    "    to.transform(to.y_names, partial(_decode_cats, {n: self.vocab for n in to.y_names}), all_col=False)\n",
    "    return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NormalizeTS(TabularProc):\n",
    "    \"Normalize the x variables.\"\n",
    "    order = 2\n",
    "    def setups(self, dsets): self.means,self.stds = dsets.xs.mean(),dsets.xs.std(ddof=0)+1e-7\n",
    "    def encodes(self, to): to.conts = (to.xs-self.means) / self.stds\n",
    "    def decodes(self, to): to.conts = (to.xs*self.stds ) + self.means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@Normalize\n",
    "def setups(self, to:TabularTS):\n",
    "    self.means,self.stds = getattr(to, 'train', to).xs.mean(),getattr(to, 'train', to).xs.std(ddof=0)+1e-7\n",
    "    return self(to)\n",
    "\n",
    "@Normalize\n",
    "def encodes(self, to:TabularTS):\n",
    "    to.xs = (to.xs-self.means) / self.stds\n",
    "    return to\n",
    "\n",
    "@Normalize\n",
    "def decodes(self, to:TabularTS):\n",
    "    to.xs = (to.xs*self.stds ) + self.means\n",
    "    return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = Normalize()\n",
    "df = df_train.loc[:, [x_cols[0]]]\n",
    "to = TSPandas(df, norm, x_names=x_cols[0])\n",
    "x = df.values.squeeze()\n",
    "m,s = x.mean(),x.std()\n",
    "test_eq(norm.means[x_cols[0]], m)\n",
    "test_close(norm.stds[x_cols[0]], s)\n",
    "test_close(to[x_cols[0]].values, (x-m)/s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _maybe_expand(o): return o[:,None] if o.ndim==1 else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tensor([[2.,3.],[4.,5.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ReadTSBatch(ItemTransform):\n",
    "    def __init__(self, to): self.to = to\n",
    "\n",
    "    def encodes(self, to):\n",
    "        res = (tensor(to.xs).float().unsqueeze(1), )\n",
    "        ys = [n for n in to.y_names if n in to.items.columns]\n",
    "        if len(ys) == len(to.y_names): res = res + (tensor(to.targ),)\n",
    "        if to.device is not None: res = to_device(res, to.device)\n",
    "        return res\n",
    "\n",
    "    def decodes(self, o):\n",
    "        o = [_maybe_expand(o_) for o_ in to_np(o) if o_.size != 0]\n",
    "        vals = np.concatenate(o, axis=1)\n",
    "        try: df = pd.DataFrame(vals, columns=self.to.all_col_names)\n",
    "        except: df = pd.DataFrame(vals, columns=self.to.x_names)\n",
    "        to = self.to.new(df)\n",
    "        return to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TSPandas(df_train, None, x_names=x_cols, y_names='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline: Categorize"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.procs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_batch(x: TabularTS, y, its, max_n=10, ctxs=None):\n",
    "    x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind\n",
    "_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates()\n",
    "class TabularTSDataloader(TfmdDL):\n",
    "    do_item = noops\n",
    "    def __init__(self, dataset, bs=16, shuffle=False, after_batch=None, num_workers=0, **kwargs):\n",
    "        if after_batch is None: after_batch = L(TransformBlock().batch_tfms)+ReadTSBatch(dataset)\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)\n",
    "\n",
    "    def create_batch(self, b): return self.dataset.iloc[b]\n",
    "\n",
    "TSPandas._dl_type = TabularTSDataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(range_of(df_train))\n",
    "to = TSPandas(df_test, norm, x_names=x_cols, y_names='target', splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = TabularTSDataloader(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_dl(dl):\n",
    "    for x,y in iter(dl):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 0 ns, total: 128 ms\n",
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "%time cycle_dl(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def stack_train_valid(df_train, df_valid):\n",
    "    \"Stack df_train and df_valid, adds `valid_col`=True/False for df_valid/df_train\"\n",
    "    return pd.concat([df_train.assign(valid_col=False), df_valid.assign(valid_col=True)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries_fastai.models import create_inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TSPandas(stack_train_valid(df_train, df_test), norm, x_names=x_cols, y_names='target', splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = to.dataloaders(32, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = create_inception(1, len(dls.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, inception, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dls.train.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 1024])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>1.035760</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.343518</td>\n",
       "      <td>0.262926</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.280191</td>\n",
       "      <td>0.144124</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226884</td>\n",
       "      <td>0.115465</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.179048</td>\n",
       "      <td>0.098044</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.ipynb.\n",
      "Converted 02_models.ipynb.\n",
      "Converted 03_tabular.ipynb.\n",
      "Converted 99_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
